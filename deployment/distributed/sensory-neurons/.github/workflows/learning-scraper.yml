name: Learning Scraper

on:
  repository_dispatch:
    types: [scrape_request]
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to scrape'
        required: true
      recipe_id:
        description: 'Failed recipe ID'
        required: false
      priority:
        description: 'Task priority'
        required: false
        default: 'normal'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        pip install playwright beautifulsoup4 httpx python-dotenv
        playwright install chromium
    
    - name: Run learning scraper
      env:
        SYNAPSE_HUB_URL: ${{ secrets.SYNAPSE_HUB_URL }}
        SYNAPSE_API_KEY: ${{ secrets.SYNAPSE_API_KEY }}
        TARGET_URL: ${{ github.event.client_payload.url || github.event.inputs.url }}
        FAILED_RECIPE_ID: ${{ github.event.client_payload.recipe_id || github.event.inputs.recipe_id }}
      run: |
        echo "Learning scraper would run here"
        echo "URL: $TARGET_URL"
        echo "Recipe ID: $FAILED_RECIPE_ID"
        
        # Simulate successful completion
        curl -X POST "$SYNAPSE_HUB_URL/v1/jobs/callback" \
          -H "Authorization: Bearer $SYNAPSE_API_KEY" \
          -H "Content-Type: application/json" \
          -d '{
            "job_id": "test_job",
            "status": "completed",
            "component": "sensory_neurons",
            "result": {
              "success": true,
              "message": "Learning scraper completed successfully"
            }
          }' || echo "Callback failed (expected if hub not ready)"